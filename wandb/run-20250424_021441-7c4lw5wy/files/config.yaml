_wandb:
    value:
        cli_version: 0.19.6
        m: []
        python_version: 3.10.0
        t:
            "1":
                - 1
                - 5
                - 11
                - 41
                - 49
                - 51
                - 53
                - 55
                - 71
                - 105
            "2":
                - 1
                - 5
                - 11
                - 41
                - 49
                - 51
                - 53
                - 55
                - 71
                - 105
            "3":
                - 13
                - 23
                - 55
            "4": 3.10.0
            "5": 0.19.6
            "6": 4.47.1
            "8":
                - 5
            "12": 0.19.6
            "13": linux-x86_64
batch_size_training:
    value: 8
bf16:
    value: false
c_thought:
    value: 1
coconut:
    value: true
cot:
    value: false
debug:
    value: false
epochs_per_stage:
    value: 1
gradient_accumulation_steps:
    value: 1
load_model_path:
    value: checkpoint/cladder-cot_llama_1B/checkpoint_12
lr:
    value: 2e-05
max_latent_stage:
    value: 6
model_id:
    value: meta-llama/Llama-3.2-1B
name:
    value: cladder-coconut_llama_1B
no_cot:
    value: false
no_thoughts:
    value: false
num_epochs:
    value: 8
only_eval:
    value: false
pad_latent_to_max:
    value: true
project:
    value: coconut
reset_optimizer:
    value: true
resume:
    value: 1
save_only_improve:
    value: false
save_path:
    value: checkpoint
seed:
    value: 0
train_path:
    value: data/cladder_train.json
train_size:
    value: 10000
uniform_prob:
    value: 0
val_path:
    value: data/cladder_valid.json
val_size:
    value: 100
weight_decay:
    value: 0.01
