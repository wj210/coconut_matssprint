# need 4 gpus

project: coconut
save_path: checkpoint
name: gsm-coconut-eval_llama_1B

only_eval: True

coconut: True
cot: False
no_thoughts: False
no_cot: False

c_thought: 2
epochs_per_stage: 3
max_latent_stage: 3
pad_latent_to_max: True
val_size: 2000

save_only_improve: False
uniform_prob: 0.0
model_id: "meta-llama/Llama-3.2-1B"
load_model_path: checkpoint/gsm-coconut_llama_1B_coconut/checkpoint_5
seed: 0
resume: 15
bf16: False
train_path: data/gsm_train.json
val_path: data/gsm_test.json
reset_optimizer: True
batch_size_training: 16
debug: False
gradient_accumulation_steps: 1
num_epochs: 25
lr: !!float "1e-4"
weight_decay: 0.01