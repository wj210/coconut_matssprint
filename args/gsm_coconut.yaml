# need 4 gpus

project: coconut
save_path: checkpoint
name: gsm-coconut_3_llama_1B

only_eval: False

coconut: True
cot: False
no_thoughts: False
no_cot: False

c_thought: 1
epochs_per_stage: 1
max_latent_stage: 3
pad_latent_to_max: True
train_size: 20000
val_size: 100

save_only_improve: False
uniform_prob: 0.0
model_id: "meta-llama/Llama-3.2-1B"
load_model_path: checkpoint/gsm-cot_3_llama_1B/checkpoint_3
seed: 0
resume: 1
bf16: False
train_path: data/gsm_train_3.json
val_path: data/gsm_valid_3.json
reset_optimizer: True
batch_size_training: 16
debug: False
gradient_accumulation_steps: 1
num_epochs: 5
lr: !!float "2e-5"
weight_decay: 0.01
# use_lora: False
# lora_r: 16
# lora_alpha: 16
# lora_dropout: 0.05
# lora_target_modules: ["q_proj", "k_proj", "v_proj", "o_proj"]